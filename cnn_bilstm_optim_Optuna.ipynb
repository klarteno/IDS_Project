{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' \\n¤ in colab:\\n\\n!pip install optuna\\n!pip install import_ipynb\\n!pip install torchmetrics\\n\\n'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "''' \n",
    "¤ in colab:\n",
    "\n",
    "!pip install optuna\n",
    "!pip install import_ipynb\n",
    "!pip install torchmetrics\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\androgo\\anaconda3\\envs\\pytorch_env\\lib\\site-packages\\tqdm\\auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import optuna\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import import_ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\" \\n¤ in colab:\\n\\nfrom google.colab import drive\\ndrive.mount('/content/drive', force_remount=True)\\n%cd '/content/drive/My Drive/Colab Notebooks/IDS_Project'\\n\""
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "''' \n",
    "¤ in colab:\n",
    "\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive', force_remount=True)\n",
    "%cd '/content/drive/My Drive/Colab Notebooks/IDS_Project'\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'pwd' is not recognized as an internal or external command,\n",
      "operable program or batch file.\n"
     ]
    }
   ],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from neural_net_model_train import train_net_model, test_net_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEVICE:  cuda\n",
      "shape of X:  (2827876, 78)\n",
      "number of labels of y:  15\n",
      "Class labels:  ['BENIGN' 'DDoS' 'PortScan' 'Bot' 'Infiltration'\n",
      " 'Web Attack � Brute Force' 'Web Attack � XSS'\n",
      " 'Web Attack � Sql Injection' 'FTP-Patator' 'SSH-Patator' 'DoS slowloris'\n",
      " 'DoS Slowhttptest' 'DoS Hulk' 'DoS GoldenEye' 'Heartbleed']\n",
      "\n",
      "\n",
      " After spliting the data:\n",
      "training data shape: (2120907, 23)\n",
      "test data shape: (706969, 23)\n",
      "training data shape: (2120907,)\n",
      "test data shape: (706969,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\androgo\\Documents\\Python Scripts\\IDS\\CICIDS2017_notebooks\\IDS_Project\\utils_data_prep_py.py:131: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.X_train = torch.tensor(X_train, dtype = torch.float32).clone().detach()\n"
     ]
    }
   ],
   "source": [
    "from utils_data_prep_py import get_dataloaders, get_input_size, get_number_of_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader,test_loader = get_dataloaders()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_size = get_input_size()\n",
    "number_of_classes = get_number_of_classes()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def weights_init(m):\n",
    "    if isinstance(m, nn.Conv1d):\n",
    "      nn.init.kaiming_uniform_(m.weight.data,nonlinearity='leaky_relu')\n",
    "      if m.bias is not None:\n",
    "          nn.init.constant_(m.bias.data, 0)\n",
    "    elif isinstance(m, nn.Linear):\n",
    "        torch.nn.init.kaiming_uniform_(m.weight.data,nonlinearity='leaky_relu')\n",
    "        if m.bias is not None:\n",
    "          nn.init.constant_(m.bias.data, 0)\n",
    "    elif isinstance(m, nn.BatchNorm1d):\n",
    "        nn.init.constant_(m.weight.data, 1)\n",
    "        nn.init.constant_(m.bias.data, 0)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "# remove Dropout because is still researched how to appply to Conv , some details here:\n",
    "# https://www.kdnuggets.com/2018/09/dropout-convolutional-networks.html\n",
    "\n",
    "\n",
    "# Build a model by implementing define-by-run design from Optuna\n",
    "def define_model(trial, input_features, numClasses):\n",
    "    \n",
    "    no_layers = trial.suggest_int(\"n_layers\", 2, 7)\n",
    "    layers = []\n",
    "    num_groups = 4 \n",
    "    \n",
    "    for i in range(no_layers):\n",
    "        \n",
    "        out_features = trial.suggest_int(\"n_units_l{}\".format(i), 25, 257)\n",
    "        \n",
    "        layers.append(nn.Conv1d(input_features, out_features,kernel_size= 1)) \n",
    "        #num_groups must divide out_features but if out_features is prime than num_groups=1 ,so 1 is good?\n",
    "        #layers.append(nn.GroupNorm(num_groups, out_features))\n",
    "        layers.append(nn.MaxPool1d(kernel_size=1))\n",
    "\n",
    "        # instead of GroupNorm it is used BatchNorm1d because https://www.researchgate.net/publication/361788277_Understanding_and_Improving_Group_Normalization\n",
    "        layers.append(nn.BatchNorm1d(out_features))\n",
    "        layers.append(nn.LeakyReLU())\n",
    "        drop_procentages = trial.suggest_float(\"dropout_l{}\".format(i), 0.1, 0.5)\n",
    "        # layers.append(nn.Dropout(drop_procentages))\n",
    "        \n",
    "        input_features = out_features\n",
    "        \n",
    "    drop_procentages = trial.suggest_float(\"dropout_l{}\".format(i), 0.1, 0.5)\n",
    "    layers.append(nn.LSTM(\n",
    "            input_size=1, hidden_size = input_features, num_layers=2, batch_first=True,  dropout=drop_procentages, bidirectional=True\n",
    "        ))\n",
    "    layers.append(nn.Linear(input_features * 2, numClasses))\n",
    "        \n",
    "    net_cnn_bilstm = nn.Sequential(*layers)\n",
    "    net_cnn_bilstm.apply(weights_init)\n",
    "        \n",
    "\n",
    "    def init_func(self):\n",
    "        super(NetModel, self).__init__()\n",
    "       \n",
    "    no_layers=len(layers)\n",
    "    def forward_func(self, inputs, no_layers=no_layers): \n",
    "        outputs=inputs.unsqueeze(2)\n",
    "        i = 1\n",
    "        for index in range(1,no_layers + 1):\n",
    "            outputs = getattr(self, f\"cv\"+ str(index))(outputs) \n",
    "            assert not torch.isnan(outputs).any()\n",
    "\n",
    "            outputs = getattr(self, f\"maxp\"+ str(index))(outputs) \n",
    "            assert not torch.isnan(outputs).any()\n",
    "\n",
    "            outputs = getattr(self, f\"bn\"+ str(index))(outputs) \n",
    "            assert not torch.isnan(outputs).any()\n",
    "\n",
    "            outputs = getattr(self, f\"lrel\"+ str(index))(outputs) \n",
    "            outputs = getattr(self, f\"drop\"+ str(index))(outputs) \n",
    "\n",
    "        h0 = torch.zeros(self.n_layers * 2, outputs.size(0), self.hidden_size_lstm).to(DEVICE)\n",
    "        c0 = torch.zeros(self.n_layers * 2, outputs.size(0), self.hidden_size_lstm).to(DEVICE)\n",
    "\n",
    "        outputs = outputs.squeeze(2)\n",
    "        \n",
    "        outputs, hidden = getattr(self, f\"bi_lstm\")(outputs, (h0, c0)) \n",
    "        assert not torch.isnan(outputs).any()\n",
    "\n",
    "        outputs = outputs[:, -1, :]\n",
    "        outputs, hidden = getattr(self, f\"fc_output\")(outputs) \n",
    "        assert not torch.isnan(outputs).any()\n",
    "        print('----------finished-------------')\n",
    "        return outputs\n",
    "    \n",
    "    NetModel = type(\n",
    "    'NetModel',\n",
    "    (nn.Module,),\n",
    "    {\n",
    "        '__init__': init_func,\n",
    "        'forward': forward_func,\n",
    "    })\n",
    "    cnn_bilstm_model = NetModel()\n",
    "\n",
    "    # super(CNN_BILSTM, self).__init__()\n",
    "    linear_output = layers.pop()\n",
    "    bi_lstm = layers.pop()\n",
    "    \n",
    "    i = 0\n",
    "    index=1\n",
    "    print('----------len(layers)',len(layers))\n",
    "    while i<len(layers):\n",
    "        setattr(cnn_bilstm_model,'cv'+str(index),   layers[i])\n",
    "        setattr(cnn_bilstm_model,'maxp'+str(index), layers[i+1])\n",
    "        setattr(cnn_bilstm_model,'bn'+str(index),   layers[i+2])\n",
    "        setattr(cnn_bilstm_model,'lrel'+str(index), layers[i+3])\n",
    "        setattr(cnn_bilstm_model,'drop'+str(index), layers[i+4])\n",
    "        index = index + 1\n",
    "        print(index)\n",
    "        i = i + 5\n",
    "            \n",
    "    setattr(cnn_bilstm_model,'bi_lstm', bi_lstm)\n",
    "    setattr(cnn_bilstm_model,'fc_output', linear_output)\n",
    "    \n",
    "        \n",
    "\n",
    "    return cnn_bilstm_model \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Build a model by implementing define-by-run design from Optuna\n",
    "def define_model(trial, input_features, numClasses):\n",
    "    \n",
    "    no_layers = trial.suggest_int(\"n_layers\", 2, 7)\n",
    "    layers = []\n",
    "    num_groups = 4 \n",
    "    \n",
    "    \n",
    "    def init_func(self):\n",
    "        super(NetModel, self).__init__()\n",
    "       \n",
    "    def forward_func(self, inputs, no_layers=no_layers): \n",
    "        outputs=inputs.unsqueeze(2)\n",
    "        \n",
    "        for index in range(1,no_layers + 1):\n",
    "            outputs = getattr(self, f\"cv\"+ str(index))(outputs) \n",
    "            assert not torch.isnan(outputs).any()\n",
    "\n",
    "            outputs = getattr(self, f\"avgp\"+ str(index))(outputs) \n",
    "            assert not torch.isnan(outputs).any()\n",
    "\n",
    "            outputs = getattr(self, f\"bn\"+ str(index))(outputs) \n",
    "            assert not torch.isnan(outputs).any()\n",
    "\n",
    "            outputs = getattr(self, f\"lrel\"+ str(index))(outputs) \n",
    "\n",
    "        lstm_layers=2\n",
    "        h0 = torch.zeros(lstm_layers * 2, outputs.size(0), self.hidden_size_lstm).to(DEVICE)\n",
    "        c0 = torch.zeros(lstm_layers * 2, outputs.size(0), self.hidden_size_lstm).to(DEVICE)\n",
    "\n",
    "        outputs1 = outputs.squeeze(2)\n",
    "        #outputs = outputs.transpose(1, 2)\n",
    "        \n",
    "        \n",
    "        outputs, hidden = getattr(self, f\"bi_lstm\")(outputs, (h0, c0)) \n",
    "        assert not torch.isnan(outputs).any()\n",
    "\n",
    "        outputs2 = outputs[:, -1, :]\n",
    "        outputs = outputs.permute(0, 2, 1)[:, -1, :]\n",
    "\n",
    "        outputs = getattr(self, f\"fc_output\")(outputs) \n",
    "        assert not torch.isnan(outputs).any()\n",
    "\n",
    "        \n",
    "        return outputs\n",
    "    \n",
    "    NetModel = type(\n",
    "    'NetModel',\n",
    "    (nn.Module,),\n",
    "    {\n",
    "        '__init__': init_func,\n",
    "        'forward': forward_func,\n",
    "    })\n",
    "    \n",
    "    cnn_bilstm_model = NetModel()\n",
    "    \n",
    "    for i in range(no_layers):\n",
    "        out_features = trial.suggest_int(\"n_units_l{}\".format(i), 25, 257)\n",
    "        \n",
    "        setattr(cnn_bilstm_model,'cv'+str(i+1),   nn.Conv1d(input_features, out_features,kernel_size= 1)) \n",
    "        # layers.append(nn.MaxPool1d(kernel_size=1))\n",
    "        setattr(cnn_bilstm_model,'avgp'+str(i+1), nn.AvgPool1d(kernel_size=1))\n",
    "        # setattr(cnn_bilstm_model,'maxp'+str(i+1), nn.MaxPool1d(kernel_size=1))\n",
    "        setattr(cnn_bilstm_model,'bn'+str(i+1),   nn.BatchNorm1d(out_features))\n",
    "        setattr(cnn_bilstm_model,'lrel'+str(i+1),nn.LeakyReLU())\n",
    "        \n",
    "        input_features = out_features\n",
    "\n",
    "\n",
    "    setattr(cnn_bilstm_model,'hidden_size_lstm',input_features)\n",
    "         \n",
    "    drop_procentages = trial.suggest_float(\"dropout_l{}\".format(i), 0.1, 0.5)\n",
    "     \n",
    "    setattr(cnn_bilstm_model,'bi_lstm', nn.LSTM(\n",
    "            input_size=1, hidden_size = input_features, num_layers=2, batch_first=True,  dropout=drop_procentages, bidirectional=True\n",
    "        ))\n",
    "    setattr(cnn_bilstm_model,'fc_output', nn.Linear(input_features, numClasses))\n",
    "\n",
    "    cnn_bilstm_model.apply(weights_init)\n",
    "\n",
    "    return cnn_bilstm_model \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "# remove Dropout because is still researched how to appply to Conv , some details here:\n",
    "# https://www.kdnuggets.com/2018/09/dropout-convolutional-networks.html\n",
    "\n",
    "\n",
    "# Build a model by implementing define-by-run design from Optuna\n",
    "def define_model(trial, input_features, numClasses, use_gru_instead_of_lstm=True):\n",
    "    \n",
    "    no_layers = trial.suggest_int(\"n_layers\", 2, 7)\n",
    "    layers = []\n",
    "    num_groups = 4 \n",
    "    \n",
    "    #to be optimized by optuna?\n",
    "    rnn_stacked_layers=2\n",
    "    \n",
    "    \n",
    "    def init_func(self):\n",
    "        super(NetModel, self).__init__()\n",
    "       \n",
    "    def forward_func(self, inputs, no_layers=no_layers): \n",
    "        # add 1 dimension  for the conv1d\n",
    "        outputs=inputs.unsqueeze(2)\n",
    "        \n",
    "        for index in range(1,no_layers + 1):\n",
    "            outputs = getattr(self, f\"cv\"+ str(index))(outputs) \n",
    "            assert not torch.isnan(outputs).any()\n",
    "\n",
    "            outputs = getattr(self, f\"avgp\"+ str(index))(outputs) \n",
    "            assert not torch.isnan(outputs).any()\n",
    "\n",
    "            outputs = getattr(self, f\"bn\"+ str(index))(outputs) \n",
    "            assert not torch.isnan(outputs).any()\n",
    "\n",
    "            outputs = getattr(self, f\"lrel\"+ str(index))(outputs) \n",
    "\n",
    "        \n",
    "        \n",
    "        if use_gru_instead_of_lstm: \n",
    "            h0 = torch.zeros(rnn_stacked_layers * 2, outputs.size(0), self.hidden_size_lstm).to(DEVICE)\n",
    "\n",
    "            # outputs1 = outputs.squeeze(2)\n",
    "            #outputs = outputs.transpose(1, 2)\n",
    "            outputs, hidden = getattr(self, f\"bi_gru\")(outputs, h0)        \n",
    "        else:\n",
    "            h0 = torch.zeros(rnn_stacked_layers * 2, outputs.size(0), self.hidden_size_lstm).to(DEVICE)\n",
    "            c0 = torch.zeros(rnn_stacked_layers * 2, outputs.size(0), self.hidden_size_lstm).to(DEVICE)\n",
    "\n",
    "            # outputs1 = outputs.squeeze(2)\n",
    "            #outputs = outputs.transpose(1, 2)\n",
    "            outputs, hidden = getattr(self, f\"bi_lstm\")(outputs, (h0, c0)) \n",
    "        assert not torch.isnan(outputs).any()\n",
    "\n",
    "        # outputs2 = outputs[:, -1, :]\n",
    "        outputs = outputs.permute(0, 2, 1)[:, -1, :]\n",
    "\n",
    "        outputs = getattr(self, f\"fc_output\")(outputs) \n",
    "        assert not torch.isnan(outputs).any()\n",
    "\n",
    "        \n",
    "        return outputs\n",
    "    \n",
    "    NetModel = type(\n",
    "    'NetModel',\n",
    "    (nn.Module,),\n",
    "    {\n",
    "        '__init__': init_func,\n",
    "        'forward': forward_func,\n",
    "    })\n",
    "    \n",
    "    cnn_bilstm_model = NetModel()\n",
    "    \n",
    "    for i in range(no_layers):\n",
    "        out_features = trial.suggest_int(\"n_units_l{}\".format(i), 25, 257)\n",
    "        \n",
    "        setattr(cnn_bilstm_model,'cv'+str(i+1),   nn.Conv1d(input_features, out_features,kernel_size= 1)) \n",
    "        # layers.append(nn.MaxPool1d(kernel_size=1))\n",
    "        setattr(cnn_bilstm_model,'avgp'+str(i+1), nn.AvgPool1d(kernel_size=1))\n",
    "        # setattr(cnn_bilstm_model,'maxp'+str(i+1), nn.MaxPool1d(kernel_size=1))\n",
    "        setattr(cnn_bilstm_model,'bn'+str(i+1),   nn.BatchNorm1d(out_features))\n",
    "        setattr(cnn_bilstm_model,'lrel'+str(i+1),nn.LeakyReLU())\n",
    "        \n",
    "        input_features = out_features\n",
    "\n",
    "\n",
    "    setattr(cnn_bilstm_model,'hidden_size_lstm',input_features)\n",
    "         \n",
    "    drop_procentages = trial.suggest_float(\"dropout_l{}\".format(i), 0.1, 0.5)\n",
    "     \n",
    "    if use_gru_instead_of_lstm: \n",
    "        # input_size=1 because the data is 1D\n",
    "        setattr(cnn_bilstm_model,'bi_gru', nn.GRU(\n",
    "                input_size=1, hidden_size = input_features, num_layers = rnn_stacked_layers, batch_first=True,  dropout=drop_procentages, bidirectional=True\n",
    "            ))\n",
    "    else:\n",
    "        setattr(cnn_bilstm_model,'bi_lstm', nn.LSTM(\n",
    "                input_size=1, hidden_size = input_features, num_layers = rnn_stacked_layers, batch_first=True,  dropout=drop_procentages, bidirectional=True\n",
    "            ))   \n",
    "    \n",
    "    setattr(cnn_bilstm_model,'fc_output', nn.Linear(input_features, numClasses))\n",
    "\n",
    "    cnn_bilstm_model.apply(weights_init)\n",
    "\n",
    "    return cnn_bilstm_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Hyperparameter Tuning with Accuracy Pruning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-09-09 21:50:43,393]\u001b[0m A new study created in memory with name: no-name-b46f0821-ddb4-4e33-8105-69e9e2e387d7\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "231\n",
      "NetModel(\n",
      "  (cv1): Conv1d(23, 159, kernel_size=(1,), stride=(1,))\n",
      "  (avgp1): AvgPool1d(kernel_size=(1,), stride=(1,), padding=(0,))\n",
      "  (bn1): BatchNorm1d(159, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (lrel1): LeakyReLU(negative_slope=0.01)\n",
      "  (cv2): Conv1d(159, 37, kernel_size=(1,), stride=(1,))\n",
      "  (avgp2): AvgPool1d(kernel_size=(1,), stride=(1,), padding=(0,))\n",
      "  (bn2): BatchNorm1d(37, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (lrel2): LeakyReLU(negative_slope=0.01)\n",
      "  (cv3): Conv1d(37, 98, kernel_size=(1,), stride=(1,))\n",
      "  (avgp3): AvgPool1d(kernel_size=(1,), stride=(1,), padding=(0,))\n",
      "  (bn3): BatchNorm1d(98, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (lrel3): LeakyReLU(negative_slope=0.01)\n",
      "  (cv4): Conv1d(98, 220, kernel_size=(1,), stride=(1,))\n",
      "  (avgp4): AvgPool1d(kernel_size=(1,), stride=(1,), padding=(0,))\n",
      "  (bn4): BatchNorm1d(220, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (lrel4): LeakyReLU(negative_slope=0.01)\n",
      "  (cv5): Conv1d(220, 231, kernel_size=(1,), stride=(1,))\n",
      "  (avgp5): AvgPool1d(kernel_size=(1,), stride=(1,), padding=(0,))\n",
      "  (bn5): BatchNorm1d(231, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (lrel5): LeakyReLU(negative_slope=0.01)\n",
      "  (bi_gru): GRU(1, 231, num_layers=2, batch_first=True, dropout=0.10978761248683054, bidirectional=True)\n",
      "  (fc_output): Linear(in_features=231, out_features=15, bias=True)\n",
      ")\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 351/65329 [01:17<3:59:19,  4.53it/s]\n",
      "\u001b[33m[W 2022-09-09 21:52:01,276]\u001b[0m Trial 0 failed because of the following error: KeyboardInterrupt()\u001b[0m\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\androgo\\anaconda3\\envs\\pytorch_env\\lib\\site-packages\\optuna\\study\\_optimize.py\", line 196, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "  File \"C:\\Users\\androgo\\AppData\\Local\\Temp\\ipykernel_29524\\1170637482.py\", line 29, in objective\n",
      "    losses, accuracies = train_net_model(cnn_bilstm_model, optimizer, train_loader, MAX_EPOCHS, trial_optimisation=trial,trial_parameter='accuracy')\n",
      "  File \"c:\\Users\\androgo\\Documents\\Python Scripts\\IDS\\CICIDS2017_notebooks\\IDS_Project\\neural_net_model_train.py\", line 49, in train_net_model\n",
      "    outputs = net_model(batch_x)\n",
      "  File \"c:\\Users\\androgo\\anaconda3\\envs\\pytorch_env\\lib\\site-packages\\torch\\nn\\modules\\module.py\", line 1130, in _call_impl\n",
      "    return forward_call(*input, **kwargs)\n",
      "  File \"C:\\Users\\androgo\\AppData\\Local\\Temp\\ipykernel_29524\\4086871875.py\", line 42, in forward_func\n",
      "    outputs, hidden = getattr(self, f\"bi_gru\")(outputs, h0)\n",
      "  File \"c:\\Users\\androgo\\anaconda3\\envs\\pytorch_env\\lib\\site-packages\\torch\\nn\\modules\\module.py\", line 1130, in _call_impl\n",
      "    return forward_call(*input, **kwargs)\n",
      "  File \"c:\\Users\\androgo\\anaconda3\\envs\\pytorch_env\\lib\\site-packages\\torch\\nn\\modules\\rnn.py\", line 950, in forward\n",
      "    result = _VF.gru(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "KeyboardInterrupt\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\androgo\\Documents\\Python Scripts\\IDS\\CICIDS2017_notebooks\\IDS_Project\\cnn_bilstm_optim_Optuna.ipynb Cell 14\u001b[0m in \u001b[0;36m<cell line: 38>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/androgo/Documents/Python%20Scripts/IDS/CICIDS2017_notebooks/IDS_Project/cnn_bilstm_optim_Optuna.ipynb#X16sZmlsZQ%3D%3D?line=35'>36</a>\u001b[0m study \u001b[39m=\u001b[39m optuna\u001b[39m.\u001b[39mcreate_study(direction\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mmaximize\u001b[39m\u001b[39m\"\u001b[39m, sampler\u001b[39m=\u001b[39moptuna\u001b[39m.\u001b[39msamplers\u001b[39m.\u001b[39mTPESampler(), pruner\u001b[39m=\u001b[39moptuna\u001b[39m.\u001b[39mpruners\u001b[39m.\u001b[39mMedianPruner())\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/androgo/Documents/Python%20Scripts/IDS/CICIDS2017_notebooks/IDS_Project/cnn_bilstm_optim_Optuna.ipynb#X16sZmlsZQ%3D%3D?line=36'>37</a>\u001b[0m \u001b[39m# study.optimize(objective, n_trials=30)\u001b[39;00m\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/androgo/Documents/Python%20Scripts/IDS/CICIDS2017_notebooks/IDS_Project/cnn_bilstm_optim_Optuna.ipynb#X16sZmlsZQ%3D%3D?line=37'>38</a>\u001b[0m study\u001b[39m.\u001b[39;49moptimize(objective, n_trials\u001b[39m=\u001b[39;49m\u001b[39m1\u001b[39;49m)\n",
      "File \u001b[1;32mc:\\Users\\androgo\\anaconda3\\envs\\pytorch_env\\lib\\site-packages\\optuna\\study\\study.py:419\u001b[0m, in \u001b[0;36mStudy.optimize\u001b[1;34m(self, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[0;32m    315\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39moptimize\u001b[39m(\n\u001b[0;32m    316\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[0;32m    317\u001b[0m     func: ObjectiveFuncType,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    324\u001b[0m     show_progress_bar: \u001b[39mbool\u001b[39m \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m,\n\u001b[0;32m    325\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    326\u001b[0m     \u001b[39m\"\"\"Optimize an objective function.\u001b[39;00m\n\u001b[0;32m    327\u001b[0m \n\u001b[0;32m    328\u001b[0m \u001b[39m    Optimization is done by choosing a suitable set of hyperparameter values from a given\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    416\u001b[0m \u001b[39m            If nested invocation of this method occurs.\u001b[39;00m\n\u001b[0;32m    417\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 419\u001b[0m     _optimize(\n\u001b[0;32m    420\u001b[0m         study\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m,\n\u001b[0;32m    421\u001b[0m         func\u001b[39m=\u001b[39;49mfunc,\n\u001b[0;32m    422\u001b[0m         n_trials\u001b[39m=\u001b[39;49mn_trials,\n\u001b[0;32m    423\u001b[0m         timeout\u001b[39m=\u001b[39;49mtimeout,\n\u001b[0;32m    424\u001b[0m         n_jobs\u001b[39m=\u001b[39;49mn_jobs,\n\u001b[0;32m    425\u001b[0m         catch\u001b[39m=\u001b[39;49mcatch,\n\u001b[0;32m    426\u001b[0m         callbacks\u001b[39m=\u001b[39;49mcallbacks,\n\u001b[0;32m    427\u001b[0m         gc_after_trial\u001b[39m=\u001b[39;49mgc_after_trial,\n\u001b[0;32m    428\u001b[0m         show_progress_bar\u001b[39m=\u001b[39;49mshow_progress_bar,\n\u001b[0;32m    429\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\androgo\\anaconda3\\envs\\pytorch_env\\lib\\site-packages\\optuna\\study\\_optimize.py:66\u001b[0m, in \u001b[0;36m_optimize\u001b[1;34m(study, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[0;32m     64\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m     65\u001b[0m     \u001b[39mif\u001b[39;00m n_jobs \u001b[39m==\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[1;32m---> 66\u001b[0m         _optimize_sequential(\n\u001b[0;32m     67\u001b[0m             study,\n\u001b[0;32m     68\u001b[0m             func,\n\u001b[0;32m     69\u001b[0m             n_trials,\n\u001b[0;32m     70\u001b[0m             timeout,\n\u001b[0;32m     71\u001b[0m             catch,\n\u001b[0;32m     72\u001b[0m             callbacks,\n\u001b[0;32m     73\u001b[0m             gc_after_trial,\n\u001b[0;32m     74\u001b[0m             reseed_sampler_rng\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[0;32m     75\u001b[0m             time_start\u001b[39m=\u001b[39;49m\u001b[39mNone\u001b[39;49;00m,\n\u001b[0;32m     76\u001b[0m             progress_bar\u001b[39m=\u001b[39;49mprogress_bar,\n\u001b[0;32m     77\u001b[0m         )\n\u001b[0;32m     78\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m     79\u001b[0m         \u001b[39mif\u001b[39;00m n_jobs \u001b[39m==\u001b[39m \u001b[39m-\u001b[39m\u001b[39m1\u001b[39m:\n",
      "File \u001b[1;32mc:\\Users\\androgo\\anaconda3\\envs\\pytorch_env\\lib\\site-packages\\optuna\\study\\_optimize.py:160\u001b[0m, in \u001b[0;36m_optimize_sequential\u001b[1;34m(study, func, n_trials, timeout, catch, callbacks, gc_after_trial, reseed_sampler_rng, time_start, progress_bar)\u001b[0m\n\u001b[0;32m    157\u001b[0m         \u001b[39mbreak\u001b[39;00m\n\u001b[0;32m    159\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 160\u001b[0m     frozen_trial \u001b[39m=\u001b[39m _run_trial(study, func, catch)\n\u001b[0;32m    161\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[0;32m    162\u001b[0m     \u001b[39m# The following line mitigates memory problems that can be occurred in some\u001b[39;00m\n\u001b[0;32m    163\u001b[0m     \u001b[39m# environments (e.g., services that use computing containers such as CircleCI).\u001b[39;00m\n\u001b[0;32m    164\u001b[0m     \u001b[39m# Please refer to the following PR for further details:\u001b[39;00m\n\u001b[0;32m    165\u001b[0m     \u001b[39m# https://github.com/optuna/optuna/pull/325.\u001b[39;00m\n\u001b[0;32m    166\u001b[0m     \u001b[39mif\u001b[39;00m gc_after_trial:\n",
      "File \u001b[1;32mc:\\Users\\androgo\\anaconda3\\envs\\pytorch_env\\lib\\site-packages\\optuna\\study\\_optimize.py:234\u001b[0m, in \u001b[0;36m_run_trial\u001b[1;34m(study, func, catch)\u001b[0m\n\u001b[0;32m    227\u001b[0m         \u001b[39massert\u001b[39;00m \u001b[39mFalse\u001b[39;00m, \u001b[39m\"\u001b[39m\u001b[39mShould not reach.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    229\u001b[0m \u001b[39mif\u001b[39;00m (\n\u001b[0;32m    230\u001b[0m     frozen_trial\u001b[39m.\u001b[39mstate \u001b[39m==\u001b[39m TrialState\u001b[39m.\u001b[39mFAIL\n\u001b[0;32m    231\u001b[0m     \u001b[39mand\u001b[39;00m func_err \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m    232\u001b[0m     \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39misinstance\u001b[39m(func_err, catch)\n\u001b[0;32m    233\u001b[0m ):\n\u001b[1;32m--> 234\u001b[0m     \u001b[39mraise\u001b[39;00m func_err\n\u001b[0;32m    235\u001b[0m \u001b[39mreturn\u001b[39;00m frozen_trial\n",
      "File \u001b[1;32mc:\\Users\\androgo\\anaconda3\\envs\\pytorch_env\\lib\\site-packages\\optuna\\study\\_optimize.py:196\u001b[0m, in \u001b[0;36m_run_trial\u001b[1;34m(study, func, catch)\u001b[0m\n\u001b[0;32m    194\u001b[0m \u001b[39mwith\u001b[39;00m get_heartbeat_thread(trial\u001b[39m.\u001b[39m_trial_id, study\u001b[39m.\u001b[39m_storage):\n\u001b[0;32m    195\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 196\u001b[0m         value_or_values \u001b[39m=\u001b[39m func(trial)\n\u001b[0;32m    197\u001b[0m     \u001b[39mexcept\u001b[39;00m exceptions\u001b[39m.\u001b[39mTrialPruned \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m    198\u001b[0m         \u001b[39m# TODO(mamu): Handle multi-objective cases.\u001b[39;00m\n\u001b[0;32m    199\u001b[0m         state \u001b[39m=\u001b[39m TrialState\u001b[39m.\u001b[39mPRUNED\n",
      "\u001b[1;32mc:\\Users\\androgo\\Documents\\Python Scripts\\IDS\\CICIDS2017_notebooks\\IDS_Project\\cnn_bilstm_optim_Optuna.ipynb Cell 14\u001b[0m in \u001b[0;36mobjective\u001b[1;34m(trial)\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/androgo/Documents/Python%20Scripts/IDS/CICIDS2017_notebooks/IDS_Project/cnn_bilstm_optim_Optuna.ipynb#X16sZmlsZQ%3D%3D?line=22'>23</a>\u001b[0m optimizer \u001b[39m=\u001b[39m \u001b[39mgetattr\u001b[39m(optim, params[\u001b[39m'\u001b[39m\u001b[39moptimizer\u001b[39m\u001b[39m'\u001b[39m])(cnn_bilstm_model\u001b[39m.\u001b[39mparameters(), lr\u001b[39m=\u001b[39mparams[\u001b[39m'\u001b[39m\u001b[39mlearning_rate\u001b[39m\u001b[39m'\u001b[39m])\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/androgo/Documents/Python%20Scripts/IDS/CICIDS2017_notebooks/IDS_Project/cnn_bilstm_optim_Optuna.ipynb#X16sZmlsZQ%3D%3D?line=25'>26</a>\u001b[0m \u001b[39m# Get the FashionMNIST dataset.\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/androgo/Documents/Python%20Scripts/IDS/CICIDS2017_notebooks/IDS_Project/cnn_bilstm_optim_Optuna.ipynb#X16sZmlsZQ%3D%3D?line=26'>27</a>\u001b[0m \u001b[39m# train_loader, val_loader = get_mnist()\u001b[39;00m\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/androgo/Documents/Python%20Scripts/IDS/CICIDS2017_notebooks/IDS_Project/cnn_bilstm_optim_Optuna.ipynb#X16sZmlsZQ%3D%3D?line=28'>29</a>\u001b[0m losses, accuracies \u001b[39m=\u001b[39m train_net_model(cnn_bilstm_model, optimizer, train_loader, MAX_EPOCHS, trial_optimisation\u001b[39m=\u001b[39;49mtrial,trial_parameter\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39maccuracy\u001b[39;49m\u001b[39m'\u001b[39;49m)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/androgo/Documents/Python%20Scripts/IDS/CICIDS2017_notebooks/IDS_Project/cnn_bilstm_optim_Optuna.ipynb#X16sZmlsZQ%3D%3D?line=29'>30</a>\u001b[0m accuracy, test_loss \u001b[39m=\u001b[39m test_net_model(cnn_bilstm_model, test_loader)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/androgo/Documents/Python%20Scripts/IDS/CICIDS2017_notebooks/IDS_Project/cnn_bilstm_optim_Optuna.ipynb#X16sZmlsZQ%3D%3D?line=30'>31</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m'\u001b[39m\u001b[39mtest loss\u001b[39m\u001b[39m'\u001b[39m,test_loss)\n",
      "File \u001b[1;32mc:\\Users\\androgo\\Documents\\Python Scripts\\IDS\\CICIDS2017_notebooks\\IDS_Project\\neural_net_model_train.py:49\u001b[0m, in \u001b[0;36mtrain_net_model\u001b[1;34m(net_model, optimizer, trainloader, MAX_EPOCHS, trial_optimisation, trial_parameter)\u001b[0m\n\u001b[0;32m     45\u001b[0m \u001b[39mfor\u001b[39;00m step, (batch_x, batch_y) \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(tqdm\u001b[39m.\u001b[39mtqdm(trainloader),\u001b[39m0\u001b[39m):            \n\u001b[0;32m     47\u001b[0m     batch_x, batch_y \u001b[39m=\u001b[39m batch_x\u001b[39m.\u001b[39mto(DEVICE), batch_y\u001b[39m.\u001b[39mto(DEVICE)\n\u001b[1;32m---> 49\u001b[0m     outputs \u001b[39m=\u001b[39m net_model(batch_x)\n\u001b[0;32m     50\u001b[0m     \u001b[39massert\u001b[39;00m \u001b[39mnot\u001b[39;00m torch\u001b[39m.\u001b[39misnan(outputs)\u001b[39m.\u001b[39many()\n\u001b[0;32m     52\u001b[0m     \u001b[39m#loss = criterion(outputs, batch_y.long())  \u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\androgo\\anaconda3\\envs\\pytorch_env\\lib\\site-packages\\torch\\nn\\modules\\module.py:1130\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1126\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1127\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1128\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1129\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1130\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39m\u001b[39minput\u001b[39m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1131\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1132\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "\u001b[1;32mc:\\Users\\androgo\\Documents\\Python Scripts\\IDS\\CICIDS2017_notebooks\\IDS_Project\\cnn_bilstm_optim_Optuna.ipynb Cell 14\u001b[0m in \u001b[0;36mdefine_model.<locals>.forward_func\u001b[1;34m(self, inputs, no_layers)\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/androgo/Documents/Python%20Scripts/IDS/CICIDS2017_notebooks/IDS_Project/cnn_bilstm_optim_Optuna.ipynb#X16sZmlsZQ%3D%3D?line=37'>38</a>\u001b[0m     h0 \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mzeros(rnn_stacked_layers \u001b[39m*\u001b[39m \u001b[39m2\u001b[39m, outputs\u001b[39m.\u001b[39msize(\u001b[39m0\u001b[39m), \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhidden_size_lstm)\u001b[39m.\u001b[39mto(DEVICE)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/androgo/Documents/Python%20Scripts/IDS/CICIDS2017_notebooks/IDS_Project/cnn_bilstm_optim_Optuna.ipynb#X16sZmlsZQ%3D%3D?line=39'>40</a>\u001b[0m     \u001b[39m# outputs1 = outputs.squeeze(2)\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/androgo/Documents/Python%20Scripts/IDS/CICIDS2017_notebooks/IDS_Project/cnn_bilstm_optim_Optuna.ipynb#X16sZmlsZQ%3D%3D?line=40'>41</a>\u001b[0m     \u001b[39m#outputs = outputs.transpose(1, 2)\u001b[39;00m\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/androgo/Documents/Python%20Scripts/IDS/CICIDS2017_notebooks/IDS_Project/cnn_bilstm_optim_Optuna.ipynb#X16sZmlsZQ%3D%3D?line=41'>42</a>\u001b[0m     outputs, hidden \u001b[39m=\u001b[39m \u001b[39mgetattr\u001b[39;49m(\u001b[39mself\u001b[39;49m, \u001b[39mf\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mbi_gru\u001b[39;49m\u001b[39m\"\u001b[39;49m)(outputs, h0)        \n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/androgo/Documents/Python%20Scripts/IDS/CICIDS2017_notebooks/IDS_Project/cnn_bilstm_optim_Optuna.ipynb#X16sZmlsZQ%3D%3D?line=42'>43</a>\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/androgo/Documents/Python%20Scripts/IDS/CICIDS2017_notebooks/IDS_Project/cnn_bilstm_optim_Optuna.ipynb#X16sZmlsZQ%3D%3D?line=43'>44</a>\u001b[0m     h0 \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mzeros(rnn_stacked_layers \u001b[39m*\u001b[39m \u001b[39m2\u001b[39m, outputs\u001b[39m.\u001b[39msize(\u001b[39m0\u001b[39m), \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhidden_size_lstm)\u001b[39m.\u001b[39mto(DEVICE)\n",
      "File \u001b[1;32mc:\\Users\\androgo\\anaconda3\\envs\\pytorch_env\\lib\\site-packages\\torch\\nn\\modules\\module.py:1130\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1126\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1127\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1128\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1129\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1130\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39m\u001b[39minput\u001b[39m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1131\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1132\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[1;32mc:\\Users\\androgo\\anaconda3\\envs\\pytorch_env\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:950\u001b[0m, in \u001b[0;36mGRU.forward\u001b[1;34m(self, input, hx)\u001b[0m\n\u001b[0;32m    948\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcheck_forward_args(\u001b[39minput\u001b[39m, hx, batch_sizes)\n\u001b[0;32m    949\u001b[0m \u001b[39mif\u001b[39;00m batch_sizes \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m--> 950\u001b[0m     result \u001b[39m=\u001b[39m _VF\u001b[39m.\u001b[39;49mgru(\u001b[39minput\u001b[39;49m, hx, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_flat_weights, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbias, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mnum_layers,\n\u001b[0;32m    951\u001b[0m                      \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdropout, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtraining, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbidirectional, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbatch_first)\n\u001b[0;32m    952\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    953\u001b[0m     result \u001b[39m=\u001b[39m _VF\u001b[39m.\u001b[39mgru(\u001b[39minput\u001b[39m, batch_sizes, hx, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_flat_weights, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbias,\n\u001b[0;32m    954\u001b[0m                      \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnum_layers, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdropout, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtraining, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbidirectional)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "MAX_EPOCHS = 2\n",
    "import pprint\n",
    "# Define a set of hyperparameter values, build the model, train the model, and evaluate the accuracy\n",
    "def objective(trial):\n",
    "\n",
    "    input_features = input_size\n",
    "    numClasses = number_of_classes\n",
    "    #trial controls de parameters of the model\n",
    "    cnn_bilstm_model = define_model(trial, input_features, numClasses,use_gru_instead_of_lstm=True)\n",
    "    # cnn_bilstm_model= CNN_bilstm_model()\n",
    "    print((cnn_bilstm_model.hidden_size_lstm))\n",
    "\n",
    "    print(repr(cnn_bilstm_model))\n",
    "    # print(type(cnn_bilstm_model))\n",
    "    # print(dir(cnn_bilstm_model))\n",
    "\n",
    "    params = {\n",
    "              'learning_rate': trial.suggest_float('learning_rate', 1e-5, 1e-1),\n",
    "              'optimizer': trial.suggest_categorical(\"optimizer\", [\"Adam\", \"RMSprop\", \"SGD\"]),\n",
    "              }\n",
    "    \n",
    "    # Generate the optimizers.\n",
    "    optimizer = getattr(optim, params['optimizer'])(cnn_bilstm_model.parameters(), lr=params['learning_rate'])\n",
    "\n",
    "    \n",
    "    # Get the FashionMNIST dataset.\n",
    "    # train_loader, val_loader = get_mnist()\n",
    "\n",
    "    losses, accuracies = train_net_model(cnn_bilstm_model, optimizer, train_loader, MAX_EPOCHS, trial_optimisation=trial,trial_parameter='accuracy')\n",
    "    accuracy, test_loss = test_net_model(cnn_bilstm_model, test_loader)\n",
    "    print('test loss',test_loss)\n",
    "\n",
    "    return accuracy\n",
    " \n",
    "    \n",
    "study = optuna.create_study(direction=\"maximize\", sampler=optuna.samplers.TPESampler(), pruner=optuna.pruners.MedianPruner())\n",
    "# study.optimize(objective, n_trials=30)\n",
    "study.optimize(objective, n_trials=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-09-09 21:23:35,275]\u001b[0m A new study created in memory with name: no-name-4e33784c-41ed-4057-aecf-0f82f959b3bc\u001b[0m\n",
      "c:\\Users\\androgo\\anaconda3\\envs\\pytorch_env\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:62: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.204662891427126 and num_layers=1\n",
      "  warnings.warn(\"dropout option adds dropout after all but last \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "147\n",
      "NetModel(\n",
      "  (cv1): Conv1d(23, 67, kernel_size=(1,), stride=(1,))\n",
      "  (avgp1): AvgPool1d(kernel_size=(1,), stride=(1,), padding=(0,))\n",
      "  (bn1): BatchNorm1d(67, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (lrel1): LeakyReLU(negative_slope=0.01)\n",
      "  (cv2): Conv1d(67, 111, kernel_size=(1,), stride=(1,))\n",
      "  (avgp2): AvgPool1d(kernel_size=(1,), stride=(1,), padding=(0,))\n",
      "  (bn2): BatchNorm1d(111, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (lrel2): LeakyReLU(negative_slope=0.01)\n",
      "  (cv3): Conv1d(111, 59, kernel_size=(1,), stride=(1,))\n",
      "  (avgp3): AvgPool1d(kernel_size=(1,), stride=(1,), padding=(0,))\n",
      "  (bn3): BatchNorm1d(59, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (lrel3): LeakyReLU(negative_slope=0.01)\n",
      "  (cv4): Conv1d(59, 50, kernel_size=(1,), stride=(1,))\n",
      "  (avgp4): AvgPool1d(kernel_size=(1,), stride=(1,), padding=(0,))\n",
      "  (bn4): BatchNorm1d(50, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (lrel4): LeakyReLU(negative_slope=0.01)\n",
      "  (cv5): Conv1d(50, 147, kernel_size=(1,), stride=(1,))\n",
      "  (avgp5): AvgPool1d(kernel_size=(1,), stride=(1,), padding=(0,))\n",
      "  (bn5): BatchNorm1d(147, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (lrel5): LeakyReLU(negative_slope=0.01)\n",
      "  (bi_lstm): LSTM(1, 147, batch_first=True, dropout=0.204662891427126, bidirectional=True)\n",
      "  (fc_output): Linear(in_features=147, out_features=15, bias=True)\n",
      ")\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/65329 [00:01<?, ?it/s]\n",
      "\u001b[33m[W 2022-09-09 21:23:36,714]\u001b[0m Trial 0 failed because of the following error: RuntimeError('Expected hidden[0] size (2, 32, 147), got [4, 32, 147]')\u001b[0m\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\androgo\\anaconda3\\envs\\pytorch_env\\lib\\site-packages\\optuna\\study\\_optimize.py\", line 196, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "  File \"C:\\Users\\androgo\\AppData\\Local\\Temp\\ipykernel_29524\\1957460143.py\", line 29, in objective\n",
      "    losses, accuracies = train_net_model(cnn_bilstm_model, optimizer, train_loader, MAX_EPOCHS, trial_optimisation=trial,trial_parameter='accuracy')\n",
      "  File \"c:\\Users\\androgo\\Documents\\Python Scripts\\IDS\\CICIDS2017_notebooks\\IDS_Project\\neural_net_model_train.py\", line 49, in train_net_model\n",
      "    outputs = net_model(batch_x)\n",
      "  File \"c:\\Users\\androgo\\anaconda3\\envs\\pytorch_env\\lib\\site-packages\\torch\\nn\\modules\\module.py\", line 1130, in _call_impl\n",
      "    return forward_call(*input, **kwargs)\n",
      "  File \"C:\\Users\\androgo\\AppData\\Local\\Temp\\ipykernel_29524\\4163189695.py\", line 46, in forward_func\n",
      "    outputs, hidden = getattr(self, f\"bi_lstm\")(outputs, (h0, c0))\n",
      "  File \"c:\\Users\\androgo\\anaconda3\\envs\\pytorch_env\\lib\\site-packages\\torch\\nn\\modules\\module.py\", line 1130, in _call_impl\n",
      "    return forward_call(*input, **kwargs)\n",
      "  File \"c:\\Users\\androgo\\anaconda3\\envs\\pytorch_env\\lib\\site-packages\\torch\\nn\\modules\\rnn.py\", line 767, in forward\n",
      "    self.check_forward_args(input, hx, batch_sizes)\n",
      "  File \"c:\\Users\\androgo\\anaconda3\\envs\\pytorch_env\\lib\\site-packages\\torch\\nn\\modules\\rnn.py\", line 693, in check_forward_args\n",
      "    self.check_hidden_size(hidden[0], self.get_expected_hidden_size(input, batch_sizes),\n",
      "  File \"c:\\Users\\androgo\\anaconda3\\envs\\pytorch_env\\lib\\site-packages\\torch\\nn\\modules\\rnn.py\", line 226, in check_hidden_size\n",
      "    raise RuntimeError(msg.format(expected_hidden_size, list(hx.size())))\n",
      "RuntimeError: Expected hidden[0] size (2, 32, 147), got [4, 32, 147]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unexpected exception formatting exception. Falling back to standard exception\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\androgo\\anaconda3\\envs\\pytorch_env\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3398, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"C:\\Users\\androgo\\AppData\\Local\\Temp\\ipykernel_29524\\1957460143.py\", line 38, in <cell line: 38>\n",
      "    study.optimize(objective, n_trials=1)\n",
      "  File \"c:\\Users\\androgo\\anaconda3\\envs\\pytorch_env\\lib\\site-packages\\optuna\\study\\study.py\", line 419, in optimize\n",
      "    _optimize(\n",
      "  File \"c:\\Users\\androgo\\anaconda3\\envs\\pytorch_env\\lib\\site-packages\\optuna\\study\\_optimize.py\", line 66, in _optimize\n",
      "    _optimize_sequential(\n",
      "  File \"c:\\Users\\androgo\\anaconda3\\envs\\pytorch_env\\lib\\site-packages\\optuna\\study\\_optimize.py\", line 160, in _optimize_sequential\n",
      "    frozen_trial = _run_trial(study, func, catch)\n",
      "  File \"c:\\Users\\androgo\\anaconda3\\envs\\pytorch_env\\lib\\site-packages\\optuna\\study\\_optimize.py\", line 234, in _run_trial\n",
      "    raise func_err\n",
      "  File \"c:\\Users\\androgo\\anaconda3\\envs\\pytorch_env\\lib\\site-packages\\optuna\\study\\_optimize.py\", line 196, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "  File \"C:\\Users\\androgo\\AppData\\Local\\Temp\\ipykernel_29524\\1957460143.py\", line 29, in objective\n",
      "    losses, accuracies = train_net_model(cnn_bilstm_model, optimizer, train_loader, MAX_EPOCHS, trial_optimisation=trial,trial_parameter='accuracy')\n",
      "  File \"c:\\Users\\androgo\\Documents\\Python Scripts\\IDS\\CICIDS2017_notebooks\\IDS_Project\\neural_net_model_train.py\", line 49, in train_net_model\n",
      "    outputs = net_model(batch_x)\n",
      "  File \"c:\\Users\\androgo\\anaconda3\\envs\\pytorch_env\\lib\\site-packages\\torch\\nn\\modules\\module.py\", line 1130, in _call_impl\n",
      "    return forward_call(*input, **kwargs)\n",
      "  File \"C:\\Users\\androgo\\AppData\\Local\\Temp\\ipykernel_29524\\4163189695.py\", line 46, in forward_func\n",
      "    outputs, hidden = getattr(self, f\"bi_lstm\")(outputs, (h0, c0))\n",
      "  File \"c:\\Users\\androgo\\anaconda3\\envs\\pytorch_env\\lib\\site-packages\\torch\\nn\\modules\\module.py\", line 1130, in _call_impl\n",
      "    return forward_call(*input, **kwargs)\n",
      "  File \"c:\\Users\\androgo\\anaconda3\\envs\\pytorch_env\\lib\\site-packages\\torch\\nn\\modules\\rnn.py\", line 767, in forward\n",
      "    self.check_forward_args(input, hx, batch_sizes)\n",
      "  File \"c:\\Users\\androgo\\anaconda3\\envs\\pytorch_env\\lib\\site-packages\\torch\\nn\\modules\\rnn.py\", line 693, in check_forward_args\n",
      "    self.check_hidden_size(hidden[0], self.get_expected_hidden_size(input, batch_sizes),\n",
      "  File \"c:\\Users\\androgo\\anaconda3\\envs\\pytorch_env\\lib\\site-packages\\torch\\nn\\modules\\rnn.py\", line 226, in check_hidden_size\n",
      "    raise RuntimeError(msg.format(expected_hidden_size, list(hx.size())))\n",
      "RuntimeError: Expected hidden[0] size (2, 32, 147), got [4, 32, 147]\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\androgo\\anaconda3\\envs\\pytorch_env\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 1993, in showtraceback\n",
      "    stb = self.InteractiveTB.structured_traceback(\n",
      "  File \"c:\\Users\\androgo\\anaconda3\\envs\\pytorch_env\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 1118, in structured_traceback\n",
      "    return FormattedTB.structured_traceback(\n",
      "  File \"c:\\Users\\androgo\\anaconda3\\envs\\pytorch_env\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 1012, in structured_traceback\n",
      "    return VerboseTB.structured_traceback(\n",
      "  File \"c:\\Users\\androgo\\anaconda3\\envs\\pytorch_env\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 865, in structured_traceback\n",
      "    formatted_exception = self.format_exception_as_a_whole(etype, evalue, etb, number_of_lines_of_context,\n",
      "  File \"c:\\Users\\androgo\\anaconda3\\envs\\pytorch_env\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 818, in format_exception_as_a_whole\n",
      "    frames.append(self.format_record(r))\n",
      "  File \"c:\\Users\\androgo\\anaconda3\\envs\\pytorch_env\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 736, in format_record\n",
      "    result += ''.join(_format_traceback_lines(frame_info.lines, Colors, self.has_colors, lvals))\n",
      "  File \"c:\\Users\\androgo\\anaconda3\\envs\\pytorch_env\\lib\\site-packages\\stack_data\\utils.py\", line 145, in cached_property_wrapper\n",
      "    value = obj.__dict__[self.func.__name__] = self.func(obj)\n",
      "  File \"c:\\Users\\androgo\\anaconda3\\envs\\pytorch_env\\lib\\site-packages\\stack_data\\core.py\", line 699, in lines\n",
      "    pieces = self.included_pieces\n",
      "  File \"c:\\Users\\androgo\\anaconda3\\envs\\pytorch_env\\lib\\site-packages\\stack_data\\utils.py\", line 145, in cached_property_wrapper\n",
      "    value = obj.__dict__[self.func.__name__] = self.func(obj)\n",
      "  File \"c:\\Users\\androgo\\anaconda3\\envs\\pytorch_env\\lib\\site-packages\\stack_data\\core.py\", line 647, in included_pieces\n",
      "    pos = scope_pieces.index(self.executing_piece)\n",
      "  File \"c:\\Users\\androgo\\anaconda3\\envs\\pytorch_env\\lib\\site-packages\\stack_data\\utils.py\", line 145, in cached_property_wrapper\n",
      "    value = obj.__dict__[self.func.__name__] = self.func(obj)\n",
      "  File \"c:\\Users\\androgo\\anaconda3\\envs\\pytorch_env\\lib\\site-packages\\stack_data\\core.py\", line 626, in executing_piece\n",
      "    return only(\n",
      "  File \"c:\\Users\\androgo\\anaconda3\\envs\\pytorch_env\\lib\\site-packages\\executing\\executing.py\", line 164, in only\n",
      "    raise NotOneValueFound('Expected one value, found 0')\n",
      "executing.executing.NotOneValueFound: Expected one value, found 0\n"
     ]
    }
   ],
   "source": [
    "\n",
    "MAX_EPOCHS = 2\n",
    "import pprint\n",
    "# Define a set of hyperparameter values, build the model, train the model, and evaluate the accuracy\n",
    "def objective(trial):\n",
    "\n",
    "    input_features = input_size\n",
    "    numClasses = number_of_classes\n",
    "    #trial controls de parameters of the model\n",
    "    cnn_bilstm_model = define_model(trial, input_features, numClasses,use_gru_instead_of_lstm=False)\n",
    "    # cnn_bilstm_model= CNN_bilstm_model()\n",
    "    print((cnn_bilstm_model.hidden_size_lstm))\n",
    "\n",
    "    print(repr(cnn_bilstm_model))\n",
    "    # print(type(cnn_bilstm_model))\n",
    "    # print(dir(cnn_bilstm_model))\n",
    "\n",
    "    params = {\n",
    "              'learning_rate': trial.suggest_float('learning_rate', 1e-5, 1e-1),\n",
    "              'optimizer': trial.suggest_categorical(\"optimizer\", [\"Adam\", \"RMSprop\", \"SGD\"]),\n",
    "              }\n",
    "    \n",
    "    # Generate the optimizers.\n",
    "    optimizer = getattr(optim, params['optimizer'])(cnn_bilstm_model.parameters(), lr=params['learning_rate'])\n",
    "\n",
    "    \n",
    "    # Get the FashionMNIST dataset.\n",
    "    # train_loader, val_loader = get_mnist()\n",
    "\n",
    "    losses, accuracies = train_net_model(cnn_bilstm_model, optimizer, train_loader, MAX_EPOCHS, trial_optimisation=trial,trial_parameter='accuracy')\n",
    "    accuracy, test_loss = test_net_model(cnn_bilstm_model, test_loader)\n",
    "    print('test loss',test_loss)\n",
    "\n",
    "    return accuracy\n",
    " \n",
    "    \n",
    "study = optuna.create_study(direction=\"maximize\", sampler=optuna.samplers.TPESampler(), pruner=optuna.pruners.MedianPruner())\n",
    "# study.optimize(objective, n_trials=30)\n",
    "study.optimize(objective, n_trials=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Rob_init(self, name):\n",
    "    self.name = name\n",
    "\n",
    "Robot2 = type(\"Robot2\", \n",
    "              (), \n",
    "              {\"counter\":0, \n",
    "               \"__init__\": Rob_init,\n",
    "               \"sayHello\": lambda self: \"Hi, I am \" + self.name})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Marvin\n",
      "Hi, I am Marvin\n"
     ]
    }
   ],
   "source": [
    "x = Robot2(\"Marvin\")\n",
    "print(x.name)\n",
    "print(x.sayHello())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You are driving the car\n",
      "true1\n",
      "true2\n",
      "57\n"
     ]
    }
   ],
   "source": [
    "from ast import arg\n",
    "from unicodedata import name\n",
    "\n",
    "\n",
    "def func1(x):\n",
    "    return 5+x\n",
    "\n",
    "def solve_for(self, name:str, args):\n",
    "    do = f\"cv2\"\n",
    "    if hasattr(self, do):\n",
    "            print('true1')\n",
    "            if callable(func := getattr(self, do)):\n",
    "                print('true2')\n",
    "                res=getattr(self, do)(args)\n",
    "                print(res)\n",
    "\n",
    "                # func(args)\n",
    "\n",
    "def init_func(self, color):\n",
    "        self._color = color\n",
    "        setattr(self,'cv'+str(2), func1)\n",
    "\n",
    "def drive(self):\n",
    "    print(\"You are driving the car\")\n",
    "\n",
    "Car = type(\n",
    "    'Car',\n",
    "    (object,),\n",
    "    {\n",
    "        '__init__': init_func,\n",
    "        'drive': drive,\n",
    "        'solve_for':solve_for\n",
    "    })\n",
    "\n",
    "my_car = Car('red')\n",
    "my_car.drive()\n",
    "my_car.__init__('red')\n",
    "# exec(f\"my_car.cv2()\")\n",
    "# my_car.cv2(6)\n",
    "my_car.solve_for(name='name:str',args= 52)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cv22'"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f\"cv2\" + str(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n"
     ]
    }
   ],
   "source": [
    "# Define functions f_0 to f_9\n",
    "for i in range(10):\n",
    "    exec(f\"def f_{i}(): print({i})\")\n",
    "# Run functions f_0 to f_9\n",
    "for i in range(10):\n",
    "    exec(f\"f_{i}()\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def solve_for(self, name: str):\n",
    "    do = f\"get_{name}\"\n",
    "    if hasattr(self, do) and callable(getattr(self, do)):\n",
    "        func = getattr(self, do)\n",
    "        func()\n",
    "        \n",
    "        \n",
    "def solve_for(self, name: str, *args, **kwargs):\n",
    "    do = f\"get_{name}\"\n",
    "    if hasattr(self, do) and callable(func := getattr(self, do)):\n",
    "        func(*args, **kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'y2'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'y' + str(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 2, 3, 4]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l = list(range(1, 5))\n",
    "print(l)    # [1, 2, 3, 4]\n",
    "l.pop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "exec(\"\"\"def a(x):\n",
    "...   return x+1\"\"\")\n",
    "a(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "self.v = 5\n",
      "self.v2 = 9\n"
     ]
    }
   ],
   "source": [
    "class Foo:\n",
    "    def __init__(self, v):\n",
    "        self.v = v\n",
    "        \n",
    "def my_new_method(self):\n",
    "    print(\"self.v =\", self.v)\n",
    "    \n",
    "def my_new_method2(self,x):\n",
    "    print(\"self.v2 =\", self.v+x)\n",
    "\n",
    "setattr(Foo, 'print_v', my_new_method)\n",
    "setattr(Foo, 'print_v2', my_new_method2)\n",
    "\n",
    "\n",
    "Foo(5).print_v()\n",
    "Foo(5).print_v2(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n"
     ]
    }
   ],
   "source": [
    "for index in range(7):\n",
    "    print(index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n"
     ]
    }
   ],
   "source": [
    "for index in range(1,7):\n",
    "    print(index)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.6 ('pytorch_env')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "201b6068cbed112f118c29a6393440d4ce4dc02105f31305c61d838eb972bb93"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
